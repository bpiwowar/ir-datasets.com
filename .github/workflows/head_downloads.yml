name: Downloadable Content, HEAD

on:
  schedule:
    - cron: '0 8 * * 1-6' # run every day except sunday at (around) 8:00am UTC
  workflow_dispatch:
    inputs:
      dataset:
        description: "Top-level dataset ID to run (or leave blank for all)" 
        required: false
        default: ''

jobs:

  create_branch:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - run: git checkout -b head-downloads-${{github.run_number}} --track
    - run: 'echo ${{github.run_number}} > docs/dlc/_placeholder.txt'
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/_placeholder.txt'
        message: 'touch'
        author_name: GitHub Actions
        author_email: actions@github.com





  antique:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'antique'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^antique/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/antique.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: antique'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  aol-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aol-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^aol-ia/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aol-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: aol-ia'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  aquaint:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aquaint'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^aquaint/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aquaint.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: aquaint'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  argsme:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'argsme'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^argsme/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/argsme.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: argsme'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  beir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'beir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^beir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/beir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: beir'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  c4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'c4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^c4/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/c4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: c4'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  car:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'car'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^car/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/car.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: car'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  clinicaltrials:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clinicaltrials'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clinicaltrials/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clinicaltrials.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: clinicaltrials'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  clirmatrix:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clirmatrix'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clirmatrix/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clirmatrix.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: clirmatrix'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  clueweb09:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb09'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clueweb09/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb09.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: clueweb09'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  clueweb12:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb12'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clueweb12/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb12.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: clueweb12'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  codec:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codec'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^codec/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codec.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: codec'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  codesearchnet:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codesearchnet'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^codesearchnet/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codesearchnet.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: codesearchnet'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  cord19:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cord19'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^cord19/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cord19.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: cord19'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  cranfield:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cranfield'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^cranfield/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cranfield.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: cranfield'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  disks45:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'disks45'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^disks45/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/disks45.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: disks45'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  dpr-w100:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'dpr-w100'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^dpr-w100/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/dpr-w100.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: dpr-w100'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  gov:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^gov/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: gov'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  gov2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^gov2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: gov2'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  hc4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'hc4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^hc4/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/hc4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: hc4'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  highwire:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'highwire'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^highwire/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/highwire.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: highwire'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  kilt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'kilt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^kilt/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/kilt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: kilt'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  lotte:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'lotte'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^lotte/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/lotte.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: lotte'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  medline:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'medline'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^medline/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/medline.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: medline'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  mmarco:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mmarco'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^mmarco/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mmarco.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: mmarco'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  mr-tydi:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mr-tydi'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^mr-tydi/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mr-tydi.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: mr-tydi'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  msmarco-document:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-document/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: msmarco-document'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  msmarco-document-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-document-v2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: msmarco-document-v2'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  msmarco-passage:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-passage/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: msmarco-passage'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  msmarco-passage-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-passage-v2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: msmarco-passage-v2'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  msmarco-qna:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-qna'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-qna/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-qna.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: msmarco-qna'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  natural-questions:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'natural-questions'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^natural-questions/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/natural-questions.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: natural-questions'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  neuclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'neuclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^neuclir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/neuclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: neuclir'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  nfcorpus:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nfcorpus'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^nfcorpus/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nfcorpus.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: nfcorpus'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  nyt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nyt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^nyt/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nyt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: nyt'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  pmc:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'pmc'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^pmc/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/pmc.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: pmc'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  touche:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'touche'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^touche/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/touche.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: touche'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-arabic:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-arabic'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-arabic/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-arabic.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-arabic'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-cast:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-cast'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-cast/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-cast.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-cast'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-fair-2021:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-fair-2021'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-fair-2021/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-fair-2021.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-fair-2021'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-mandarin:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-mandarin'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-mandarin/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-mandarin.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-mandarin'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-robust04:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-robust04'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-robust04/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-robust04.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-robust04'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  trec-spanish:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-spanish'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-spanish/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-spanish.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: trec-spanish'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  tripclick:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tripclick'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^tripclick/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tripclick.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: tripclick'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  tweets2013-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tweets2013-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^tweets2013-ia/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tweets2013-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: tweets2013-ia'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  vaswani:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'vaswani'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^vaswani/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/vaswani.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: vaswani'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  wapo:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wapo'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wapo/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wapo.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: wapo'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  wikiclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikiclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wikiclir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikiclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: wikiclir'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  wikir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wikir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        git commit -m 'head_downloads: wikir'
        until git push
        do
          echo trying again
          git pull --rebase --autostash
        done
        echo success

  merge_dlc:
    if: ${{ always() }}
    needs: [antique, aol-ia, aquaint, argsme, beir, c4, car, clinicaltrials, clirmatrix, clueweb09, clueweb12, codec, codesearchnet, cord19, cranfield, disks45, dpr-w100, gov, gov2, hc4, highwire, kilt, lotte, medline, mmarco, mr-tydi, msmarco-document, msmarco-document-v2, msmarco-passage, msmarco-passage-v2, msmarco-qna, natural-questions, neuclir, nfcorpus, nyt, pmc, touche, trec-arabic, trec-cast, trec-fair-2021, trec-mandarin, trec-robust04, trec-spanish, tripclick, tweets2013-ia, vaswani, wapo, wikiclir, wikir]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        ref: head-downloads-${{github.run_number}}
        fetch-depth: 0
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - run: |
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        python merge_dlc.py
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/*.json'
        message: 'from head_downloads'
        author_name: GitHub Actions
        author_email: actions@github.com
    - run: |
        git checkout master
        git merge -s recursive -Xtheirs --squash head-downloads-${{github.run_number}} --allow-unrelated-histories
        git commit -m head-downloads-${{github.run_number}}
        git push origin master
        git push origin --delete head-downloads-${{github.run_number}}
